---
layout:       post
title:        "大模型开发学习"
author:       "彭彭"
catalog:      true
header-img: "img/image-2.jpg"
tags:
    - LLM
    - RAG
    - Prompt工程
---

# 内容概要
```markmap
# 大模型简介
## 主要概念
### LLM概念
### GPT系列发展历程
### 产品线
### 涌现内容
### RAG介绍
### Langchain介绍
## 如何开发LLM
### 开发步骤
### 开发工具
## 使用codespace
# 使用LLM API
## 主要概念
### Prompt
### completion
### System Prompt
## 使用LLM
## Prompt指南
### 指令清晰和具体
### 给模型时间思考
# markmap使用例子
## Extension

- [markdown-markmap](/img/https://github.com/phoihos/vscode-markdown-markmap)

## Powered by

- <https://markmap.js.org/>
- [markmap-lib](/img/https://github.com/gera2ld/markmap-lib)

## Highlighting

- links
- **inline** ~~text~~ *styles*
- multiline
  text
- `inline code`
-   ```js
    console.log('code block');
    ```
- Katex
  - $\pm\sqrt{a^2 + b^2}$
  - $x = {-b \pm \sqrt{b^2-4ac} \over 2a}$
  - $$\int_{0}^{\infty} f(x) dx$$
```

# 第一章 大模型简介
## 主要概念
### LLM的概念
大语言模型（LLM，Large Language Model），也称大型语言模型，是一种旨在理解和生成人类语言的人工智能模型。
### GPT系列发展历程
![发展历程](/img/image.png)
### 产品线
![产品线](/img/image-1.png)

### 涌现能力（emergent abilities）
1. 上下文学习
2. 指令遵循（或指令微调）
3. 逐步推理： 采用 思维链（CoT, Chain of Thought）

### RAG 检索增强生成（RAG, Retrieval-Augmented Generation）
该架构巧妙地整合了从庞大知识库中检索到的相关信息，并以此为基础，指导大型语言模型生成更为精准的答案，从而显著提升了回答的准确性与深度。目标是解决以下LLM面临的问题：
- 信息偏差/幻觉
- 知识更新滞后性
- 内容不可追溯
- 领域专业知识能力欠缺
- 推理能力限制
- 应用场景适应性受限
- 长文本处理能力较弱

工作流程为：
数据处理-检索-增强-生成


### LangChain
LangChain 框架是一个开源工具，充分利用了大型语言模型的强大能力，以便开发各种下游应用。它的目标是为各种大型语言模型应用提供通用接口，从而简化应用程序的开发流程
![langchain](/img/image-2.png)

**核心组件**有：
- 模型输入/输出（Model I/O）：与语言模型交互的接口
- 数据连接（Data connection）：与特定应用程序的数据进行交互的接口
- 链（Chains）：将组件组合实现端到端应用。比如后续我们会将搭建检索问答链来完成检索问答。
- 记忆（Memory）：用于链的多次运行之间持久化应用程序状态；
- 代理（Agents）：扩展模型的推理能力。用于复杂的应用的调用序列；
- 回调（Callbacks）：扩展模型的推理能力。用于复杂的应用的调用序列；

**生态**：
- LangChain Community: 专注于第三方集成
- LangChain Core: LangChain 框架的核心库、核心组件
- LangChain CLI: 命令行工具，进行初始化、测试、部署
- LangServe: 部署服务，用于将 LangChain 应用程序部署到云端
- LangSmith: 开发者平台，专注于 LangChain 应用程序的开发、调试和测试，提供可视化界面和性能分析工具

## 如何开发LLM
![如何开发LLM](/img/image-3.png)
### 开发步骤
1. **确定目标**。在进行开发前，我们首先需要确定开发的目标，即要开发的应用的应用场景、目标人群、核心价值。对于个体开发者或小型开发团队而言，一般应先设定最小化目标，从构建一个 MVP（最小可行性产品）开始，逐步进行完善和优化。

3. **设计功能**。在确定开发目标后，需要设计本应用所要提供的功能，以及每一个功能的大体实现逻辑。虽然我们通过使用大模型来简化了业务逻辑的拆解，但是越清晰、深入的业务逻辑理解往往也能带来更好的 Prompt 效果。同样，对于个体开发者或小型开发团队来说，首先要确定应用的核心功能，然后延展设计核心功能的上下游功能；例如，我们想打造一款个人知识库助手，那么核心功能就是结合个人知识库内容进行问题的回答，那么其上游功能的用户上传知识库、下游功能的用户手动纠正模型回答就是我们也必须要设计实现的子功能。

5. **搭建整体架构**。目前，绝大部分大模型应用都是采用的特定数据库 + Prompt + 通用大模型的架构。我们需要针对我们所设计的功能，搭建项目的整体架构，实现从用户输入到应用输出的全流程贯通。一般来说，我们推荐基于 LangChain 框架进行开发。LangChain 提供了 Chain、Tool 等架构的实现，我们可以基于 LangChain 进行个性化定制，实现从用户输入到数据库再到大模型最后输出的整体架构连接。

7. **搭建数据库**。个性化大模型应用需要有个性化数据库进行支撑。由于大模型应用需要进行向量语义检索，一般使用诸如 Chroma 的向量数据库。在该步骤中，我们需要收集数据并进行预处理，再向量化存储到数据库中。数据预处理一般包括从多种格式向纯文本的转化，例如 PDF、MarkDown、HTML、音视频等，以及对错误数据、异常数据、脏数据进行清洗。完成预处理后，需要进行切片、向量化构建出个性化数据库。

9. **Prompt Engineering**。优质的 Prompt 对大模型能力具有极大影响，我们需要逐步迭代构建优质的 Prompt Engineering 来提升应用性能。在该步中，我们首先应该明确 Prompt 设计的一般原则及技巧，构建出一个来源于实际业务的小型验证集，基于小型验证集设计满足基本要求、具备基本能力的 Prompt。

11. **验证迭代**。验证迭代在大模型开发中是极其重要的一步，一般指通过不断发现 Bad Case 并针对性改进 Prompt Engineering 来提升系统效果、应对边界情况。在完成上一步的初始化 Prompt 设计后，我们应该进行实际业务测试，探讨边界情况，找到 Bad Case，并针对性分析 Prompt 存在的问题，从而不断迭代优化，直到达到一个较为稳定、可以基本实现目标的 Prompt 版本。

13. **前后端搭建**。完成 Prompt Engineering 及其迭代优化之后，我们就完成了应用的核心功能，可以充分发挥大语言模型的强大能力。接下来我们需要搭建前后端，设计产品页面，让我们的应用能够上线成为产品。前后端开发是非常经典且成熟的领域，此处就不再赘述，我们采用 Gradio 和 Streamlit，可以帮助个体开发者迅速搭建可视化页面实现 Demo 上线。

15. **体验优化**。在完成前后端搭建之后，应用就可以上线体验了。接下来就需要进行长期的用户体验跟踪，记录 Bad Case 与用户负反馈，再针对性进行优化即可。
### 开发工具
- 框架：LangChain
- Embedding 模型：GPT、智谱、M3E
- 数据库：Chroma
- 大模型：GPT、讯飞星火、文心一言、GLM 等
- 前后端：Gradio 和 Streamlit

## 使用codespace
1. 创建项目，使用codespace，本地vscode连接
2. 在bash里生成ssh密钥，并弄到github中（查教程）
3. 新建虚拟环境 `conda create -n llm-universe python=3.10`
4. 重启bash，不然没法激活
4. 激活虚拟环境` conda activate llm-universe`
5. 在希望存储项目的路径下克隆当前仓库 `git clone git@github.com:datawhalechina/llm-universe.git`
6. 在vscode里安装python和jupyter插件，重启vscode使插件生效
7. 打开项目里一个Jupyter Notebook，右上角选择内核-python环境-llm-universe环境（如果没有就重启，等待内核搜索）

# 第二章 使用LLM API应用开发

## 主要概念

### Prompt与Completion

一种任务专属的输入模板。即，我们每一次访问大模型的输入为一个 Prompt，而大模型给我们的返回结果则被称为 Completion。
一般而言，使用 Prompt 替代给 LLM 的输入，使用 Completion 替代 LLM 的输出。


### Temperature 

通过控制 temperature 参数来控制 LLM 生成结果的随机性与创造性。
**取值0-1之间**
- 0保守，可预测，随机性低
- 1随机性高，不同寻常

### System Prompt

System Prompt 是随着 ChatGPT API 开放并逐步得到大量使用的一个新兴概念。
在使用 ChatGPT API 时，你可以设置两种 Prompt：
- 一种是 System Prompt，该种 Prompt 内容会在整个会话过程中持久地影响模型的回复，且相比于普通 Prompt 具有更高的重要性；
- 另一种是 User Prompt，这更偏向于我们平时提到的 Prompt，即需要模型做出回复的输入。

我们一般设置 System Prompt 来对模型进行一些初始化设定，例如，我们可以在 System Prompt 中给模型设定我们希望它具备的人设如一个个人知识库助手等。System Prompt 一般在一个会话中仅有一个。

## 使用LLM
1. 获取并配置 OpenAI API key
2. 调用 OpenAI API
```
from openai import OpenAI
client = OpenAI(
    # This is the default and can be omitted
    api_key=os.environ.get("OPENAI_API_KEY"),
)
# 导入所需库
# 注意，此处我们假设你已根据上文配置了 OpenAI API Key，如没有将访问失败
completion = client.chat.completions.create(
    # 调用模型：ChatGPT-3.5
    model="gpt-3.5-turbo",
    # messages 是对话列表
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
    ]
)
```

## Prompt指南

### 原则一：编写清晰、具体的指令
1. 使用分隔符清晰地表示输入的不同部分
在编写 Prompt 时，我们可以使用各种标点符号作为“分隔符”，将不同的文本部分区分开来。分隔符就像是 Prompt 中的墙，将不同的指令、上下文、输入隔开，避免意外的混淆。你可以选择用 ```，"""，< >， ，: 等做分隔符，只要能明确起到隔断作用即可。
2. 寻求结构化的输出
按照某种格式组织的内容，例如 JSON、HTML 等。这种输出非常适合在代码中进一步解析和处理。
3. 要求模型检查是否满足条件
如果任务包含不一定能满足的假设（条件），我们可以告诉模型先检查这些假设，如果不满足，则会指 出并停止执行后续的完整流程。您还可以考虑可能出现的边缘情况及模型的应对，以避免意外的结果或 错误发生。
4. 提供少量示例
在要求模型执行实际任务之前，给模型提供一两个参考样例，让模型了解我们的要求和期望的输出样式。利用少样本样例，我们可以轻松“预热”语言模型，让它为新的任务做好准备。这是一个让模型快速上手新 任务的有效策略。

### 原则二：给模型时间去思考
1. 指定完成任务所需的步骤
下来我们将通过给定一个复杂任务，给出完成该任务的一系列步骤，来展示这一策略的效果。
首先我们描述了杰克和吉尔的故事，并给出提示词执行以下操作：
- 首先，用一句话概括三个反引号限定的文本。
- 第二，将摘要翻译成英语。
- 第三，在英语摘要中列出每个名称。
- 第四，输出包含以下键的 JSON 对象：英语摘要和人名个数。要求输出以换行符分隔。
1. 指导模型在下结论之前找出一个自己的解法
在设计 Prompt 时，我们还可以通过明确指导语言模型进行自主思考，来获得更好的效果。 举个例子，假设我们要语言模型判断一个数学问题的解答是否正确。仅仅提供问题和解答是不够的，语 言模型可能会匆忙做出错误判断。
相反，我们可以在 Prompt 中先要求语言模型自己尝试解决这个问题，思考出自己的解法，然后再与提 供的解答进行对比，判断正确性。这种先让语言模型自主思考的方式，能帮助它更深入理解问题，做出 更准确的判断。
> 在开发与应用语言模型时，需要注意它们可能生成虚假信息的风险。尽管模型经过大规模预训练，掌握 了丰富知识，但它实际上并没有完全记住所见的信息，难以准确判断自己的知识边界，可能做出错误推断。若让语言模型描述一个不存在的产品,它可能会自行构造出似是而非的细节。这被称为“幻觉” (Hallucination)，是语言模型的一大缺陷。







